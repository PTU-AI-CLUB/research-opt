{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "\n",
    "search = arxiv.Search(\n",
    "  query = \"machine learning\",\n",
    "  max_results = 10,\n",
    "  sort_by = arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "results = arxiv.Client().results(search=search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jianyuan Wang'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].authors[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Structure-from-motion (SfM) is a long-standing problem in the computer vision\\ncommunity, which aims to reconstruct the camera poses and 3D structure of a\\nscene from a set of unconstrained 2D images. Classical frameworks solve this\\nproblem in an incremental manner by detecting and matching keypoints,\\nregistering images, triangulating 3D points, and conducting bundle adjustment.\\nRecent research efforts have predominantly revolved around harnessing the power\\nof deep learning techniques to enhance specific elements (e.g., keypoint\\nmatching), but are still based on the original, non-differentiable pipeline.\\nInstead, we propose a new deep pipeline VGGSfM, where each component is fully\\ndifferentiable and thus can be trained in an end-to-end manner. To this end, we\\nintroduce new mechanisms and simplifications. First, we build on recent\\nadvances in deep 2D point tracking to extract reliable pixel-accurate tracks,\\nwhich eliminates the need for chaining pairwise matches. Furthermore, we\\nrecover all cameras simultaneously based on the image and track features\\ninstead of gradually registering cameras. Finally, we optimise the cameras and\\ntriangulate 3D points via a differentiable bundle adjustment layer. We attain\\nstate-of-the-art performance on three popular datasets, CO3D, IMC Phototourism,\\nand ETH3D.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Visual Geometry Grounded Deep Structure From Motion'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
